{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self, batch_size=16, \n",
    "                 learning_rate=0.0001, \n",
    "                 epochs=10,\n",
    "                 hidden_size = 256,\n",
    "                 embedding_dim = 128,\n",
    "                 lstm_num_layers = 3,\n",
    "                 train_size = 0.8,\n",
    "                 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                 ):\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "        self.train_size = train_size\n",
    "        self.device = device\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def get_learning_rate(self):\n",
    "        return self.learning_rate\n",
    "\n",
    "    def get_epochs(self):\n",
    "        return self.epochs\n",
    "\n",
    "    def get_hidden_size(self):\n",
    "        return self.hidden_size\n",
    "    \n",
    "    def get_embedding_dim(self):\n",
    "        return self.embedding_dim\n",
    "    \n",
    "    def get_lstm_num_layers(self):\n",
    "        return self.lstm_num_layers\n",
    "    \n",
    "    def get_train_size(self):\n",
    "        return self.train_size\n",
    "    \n",
    "    def get_device(self):\n",
    "        return self.device\n",
    "    \n",
    "hyperparams = HyperParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values (NaNs) in the dataset: meta_song.parquet\n",
      "song_id             0\n",
      "artist_id      128866\n",
      "song_length    128866\n",
      "album_id       323497\n",
      "language_id    323497\n",
      "album_month    323523\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read the Parquet file and drop duplicates based on \"song_id\" column\n",
    "df = pd.read_parquet(\"../data/meta_song.parquet\").drop_duplicates(\"song_id\")\n",
    "# Count the number of missing values (NaNs) in the DataFrame\n",
    "na_count = df.isna().sum()\n",
    "print(\"Number of missing values (NaNs) in the dataset: meta_song.parquet\")\n",
    "print(na_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_feacture_dataset(df:pd.DataFrame)->pd.DataFrame:\n",
    "    shape = df.shape[0]\n",
    "    df1 = pd.read_parquet(\"../data/meta_song_composer.parquet\").drop_duplicates(\"song_id\")\n",
    "    print(len(set(df['song_id'].unique())-set(df1['song_id'].unique())))\n",
    "    df = pd.merge(df, df1, how='left') \n",
    "    assert df.shape[0] == shape, f\"origin shape: {shape}, merge after shape: {df.shape[0]}\"\n",
    "    df2 = pd.read_parquet(\"../data/meta_song_genre.parquet\").drop_duplicates(\"song_id\")\n",
    "    print(len(set(df['song_id'].unique())-set(df2['song_id'].unique())))\n",
    "    df = pd.merge(df, df2, how='left') \n",
    "    assert df.shape[0] == shape, f\"origin shape: {shape}, merge after shape: {df.shape[0]}\"\n",
    "    df3 = pd.read_parquet(\"../data/meta_song_lyricist.parquet\").drop_duplicates(\"song_id\")\n",
    "    print(len(set(df['song_id'].unique())-set(df3['song_id'].unique())))\n",
    "    df = pd.merge(df, df3, how='left') \n",
    "    assert df.shape[0] == shape, f\"origin shape: {shape}, merge after shape: {df.shape[0]}\"\n",
    "    df4 = pd.read_parquet(\"../data/meta_song_producer.parquet\").drop_duplicates(\"song_id\")\n",
    "    print(len(set(df['song_id'].unique())-set(df4['song_id'].unique())))\n",
    "    df = pd.merge(df, df4, how='left') \n",
    "    assert df.shape[0] == shape, f\"origin shape: {shape}, merge after shape: {df.shape[0]}\"\n",
    "    df5 = pd.read_parquet(\"../data/meta_song_titletext.parquet\").drop_duplicates(\"song_id\")\n",
    "    print(len(set(df['song_id'].unique())-set(df5['song_id'].unique())))\n",
    "    df = pd.merge(df, df5, how='left') \n",
    "    assert df.shape[0] == shape, f\"origin shape: {shape}, merge after shape: {df.shape[0]}\"\n",
    "    df6 = pd.read_parquet(\"../data/meta_song.parquet\").drop_duplicates(\"song_id\")\n",
    "    print(len(set(df['song_id'].unique())-set(df6['song_id'].unique())))\n",
    "    df = pd.merge(df, df6, how='left') \n",
    "    assert df.shape[0] == shape, f\"origin shape: {shape}, merge after shape: {df.shape[0]}\"\n",
    "    print(f\"Merge finish!, now shape is : {df.shape}\")\n",
    "    return df\n",
    "\n",
    "train_source = pd.read_parquet(\"../data/label_train_source.parquet\")\n",
    "train_target = pd.read_parquet(\"../data/label_train_target.parquet\")\n",
    "test_source  = pd.read_parquet(\"../data/label_test_source.parquet\")\n",
    "\n",
    "train_source = train_source.sort_values(by=['session_id', 'listening_order'], ascending=[True, True])\n",
    "train_target = train_target.sort_values(by=['session_id', 'listening_order'], ascending=[True, True])\n",
    "test_source  = test_source.sort_values(by=['session_id', 'listening_order'], ascending=[True, True])\n",
    "\n",
    "#train_source = merge_feacture_dataset(train_source)\n",
    "#train_target = merge_feacture_dataset(train_target)\n",
    "#test_source  = merge_feacture_dataset(test_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the feactures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>unix_played_at</th>\n",
       "      <th>play_status</th>\n",
       "      <th>login_type</th>\n",
       "      <th>listening_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10952316</th>\n",
       "      <td>1</td>\n",
       "      <td>f6f06a71bb8bc38af6c0b7dae9cab00d</td>\n",
       "      <td>1660012505</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952317</th>\n",
       "      <td>1</td>\n",
       "      <td>7b48a87effd31c9c07b68ed212062854</td>\n",
       "      <td>1660012730</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952318</th>\n",
       "      <td>1</td>\n",
       "      <td>61c46d6401aab1dde7c7de23dc55c037</td>\n",
       "      <td>1660015113</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952319</th>\n",
       "      <td>1</td>\n",
       "      <td>7e54c9199aad70e35fe256d23701bad0</td>\n",
       "      <td>1660015289</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952320</th>\n",
       "      <td>1</td>\n",
       "      <td>6178580fa01b62e9b52787902c0d8ae6</td>\n",
       "      <td>1660015841</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952321</th>\n",
       "      <td>1</td>\n",
       "      <td>ab694649c65477d0bc574bf391a3f4a0</td>\n",
       "      <td>1660015842</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952322</th>\n",
       "      <td>1</td>\n",
       "      <td>5b3387fa195672dcfe979d17e4a62c9e</td>\n",
       "      <td>1660015846</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952323</th>\n",
       "      <td>1</td>\n",
       "      <td>2790c612d8d301e2f35550c75aea8c75</td>\n",
       "      <td>1660015846</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952324</th>\n",
       "      <td>1</td>\n",
       "      <td>d36c6cf30154e18e6c972704206d6b1e</td>\n",
       "      <td>1660015848</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952325</th>\n",
       "      <td>1</td>\n",
       "      <td>1cbcc681ecf7acef4948bff2eb8e39d7</td>\n",
       "      <td>1660015850</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952326</th>\n",
       "      <td>1</td>\n",
       "      <td>95eb6b55a0b6d049aadd729aaabd63de</td>\n",
       "      <td>1660015852</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952327</th>\n",
       "      <td>1</td>\n",
       "      <td>7035839edc259dcad4b1632d10eded74</td>\n",
       "      <td>1660015853</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952328</th>\n",
       "      <td>1</td>\n",
       "      <td>420af27f7145b4eebeec566c0fa7a4c1</td>\n",
       "      <td>1660015855</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952329</th>\n",
       "      <td>1</td>\n",
       "      <td>ea3083c238e4fbb01a8035816ad7101f</td>\n",
       "      <td>1660015857</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952330</th>\n",
       "      <td>1</td>\n",
       "      <td>e060390d1cfa800bd6032cfa524c57f6</td>\n",
       "      <td>1660015859</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952331</th>\n",
       "      <td>1</td>\n",
       "      <td>43fdd8f154e5c522eef60f6edfb38896</td>\n",
       "      <td>1660015860</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952332</th>\n",
       "      <td>1</td>\n",
       "      <td>8d1ee4d9df7226fd8af3c4466a48afdc</td>\n",
       "      <td>1660015862</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952333</th>\n",
       "      <td>1</td>\n",
       "      <td>2ad3043e1a7e459ddb09c5ba27e475f8</td>\n",
       "      <td>1660015863</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952334</th>\n",
       "      <td>1</td>\n",
       "      <td>7bb8fadfc8f2bf145f4b29a0325fe79a</td>\n",
       "      <td>1660016101</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952335</th>\n",
       "      <td>1</td>\n",
       "      <td>824c159701c8553b0e38f0d36ddd6197</td>\n",
       "      <td>1660016310</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          session_id                           song_id  unix_played_at  \\\n",
       "10952316           1  f6f06a71bb8bc38af6c0b7dae9cab00d      1660012505   \n",
       "10952317           1  7b48a87effd31c9c07b68ed212062854      1660012730   \n",
       "10952318           1  61c46d6401aab1dde7c7de23dc55c037      1660015113   \n",
       "10952319           1  7e54c9199aad70e35fe256d23701bad0      1660015289   \n",
       "10952320           1  6178580fa01b62e9b52787902c0d8ae6      1660015841   \n",
       "10952321           1  ab694649c65477d0bc574bf391a3f4a0      1660015842   \n",
       "10952322           1  5b3387fa195672dcfe979d17e4a62c9e      1660015846   \n",
       "10952323           1  2790c612d8d301e2f35550c75aea8c75      1660015846   \n",
       "10952324           1  d36c6cf30154e18e6c972704206d6b1e      1660015848   \n",
       "10952325           1  1cbcc681ecf7acef4948bff2eb8e39d7      1660015850   \n",
       "10952326           1  95eb6b55a0b6d049aadd729aaabd63de      1660015852   \n",
       "10952327           1  7035839edc259dcad4b1632d10eded74      1660015853   \n",
       "10952328           1  420af27f7145b4eebeec566c0fa7a4c1      1660015855   \n",
       "10952329           1  ea3083c238e4fbb01a8035816ad7101f      1660015857   \n",
       "10952330           1  e060390d1cfa800bd6032cfa524c57f6      1660015859   \n",
       "10952331           1  43fdd8f154e5c522eef60f6edfb38896      1660015860   \n",
       "10952332           1  8d1ee4d9df7226fd8af3c4466a48afdc      1660015862   \n",
       "10952333           1  2ad3043e1a7e459ddb09c5ba27e475f8      1660015863   \n",
       "10952334           1  7bb8fadfc8f2bf145f4b29a0325fe79a      1660016101   \n",
       "10952335           1  824c159701c8553b0e38f0d36ddd6197      1660016310   \n",
       "\n",
       "          play_status  login_type  listening_order  \n",
       "10952316            0           7                1  \n",
       "10952317            0           7                2  \n",
       "10952318            0           7                3  \n",
       "10952319            0           7                4  \n",
       "10952320            0           7                5  \n",
       "10952321            0           7                6  \n",
       "10952322            0           7                7  \n",
       "10952323            0           7                8  \n",
       "10952324            0           7                9  \n",
       "10952325            0           7               10  \n",
       "10952326            0           7               11  \n",
       "10952327            0           7               12  \n",
       "10952328            0           7               13  \n",
       "10952329            0           7               14  \n",
       "10952330            0           7               15  \n",
       "10952331            0           7               16  \n",
       "10952332            0           7               17  \n",
       "10952333            0           7               18  \n",
       "10952334            0           7               19  \n",
       "10952335            0           7               20  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_NaNs(df:pd.DataFrame, numerical_columns:list=None, string_columns:list=None)->pd.DataFrame:\n",
    "    for column in numerical_columns:\n",
    "        df[column].fillna(df[column].mean(), inplace=True)\n",
    "    for column in string_columns:\n",
    "        df[column].fillna(0)\n",
    "    return df\n",
    "\n",
    "def encode_unix_time(df:pd.DataFrame, sin_cos = False):\n",
    "    # Convert 'unix_played_at' to a datetime column\n",
    "    df['played_at_datetime'] = pd.to_datetime(df['unix_played_at'], unit='s')\n",
    "    if sin_cos:\n",
    "        df['hour_sin'] = np.sin(2 * np.pi * df['played_at_datetime'].dt.hour / 24)\n",
    "        df['hour_cos'] = np.cos(2 * np.pi * df['played_at_datetime'].dt.hour / 24)\n",
    "        df['minute_sin'] = np.sin(2 * np.pi * df['played_at_datetime'].dt.minute / 60)\n",
    "        df['minute_cos'] = np.cos(2 * np.pi * df['played_at_datetime'].dt.minute / 60)\n",
    "        df['second_sin'] = np.sin(2 * np.pi * df['played_at_datetime'].dt.second / 60)\n",
    "        df['second_cos'] = np.cos(2 * np.pi * df['played_at_datetime'].dt.second / 60)\n",
    "        df['month_sin'] = np.sin(2 * np.pi * df['played_at_datetime'].dt.month / 12)\n",
    "        df['month_cos'] = np.cos(2 * np.pi * df['played_at_datetime'].dt.month / 12)\n",
    "        df['year_sin'] = np.sin(2 * np.pi * df['played_at_datetime'].dt.year / 2023)\n",
    "        df['year_cos'] = np.cos(2 * np.pi * df['played_at_datetime'].dt.year / 2023)\n",
    "    else:\n",
    "        df['hour_of_day'] = df['played_at_datetime'].dt.hour / 24\n",
    "        df['minute_of_hour'] = df['played_at_datetime'].dt.minute / 60\n",
    "        df['second_of_minute'] = df['played_at_datetime'].dt.second / 60\n",
    "        df['month'] = df['played_at_datetime'].dt.month / 12\n",
    "        df['year'] = df['played_at_datetime'].dt.year / 2023\n",
    "    # Drop the specified columns from the DataFrame\n",
    "    df.drop(columns=['unix_played_at', 'played_at_datetime'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_song_ID_encode_dict(train:pd.DataFrame, test:pd.DataFrame)->dict:\n",
    "    unique_song_ids = set(train['song_id'].tolist()+test['song_id'].tolist())\n",
    "    ID_IDX = {song_id:i+1 for i,song_id in enumerate(unique_song_ids)}\n",
    "    ID_IDX[\"SOS\"]=0\n",
    "    return ID_IDX\n",
    "\n",
    "def encode_song_id(source_df:pd.DataFrame, target_df:pd.DataFrame, id2idx:dict):\n",
    "    source_df['song_id'] = source_df['song_id'].map(id2idx)\n",
    "    target_df['song_id'] = target_df['song_id'].map(id2idx)\n",
    "    return source_df, target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_IDX = get_song_ID_encode_dict(train_source, test_source)\n",
    "train_source, train_target = encode_song_id(train_source, train_target, ID_IDX)\n",
    "train_source = encode_unix_time(train_source)\n",
    "train_target = encode_unix_time(train_target)\n",
    "test_source  = encode_unix_time(test_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11445180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11445180/11445180 [08:30<00:00, 22437.65it/s]\n",
      "100%|██████████| 2861295/2861295 [00:32<00:00, 88638.59it/s]\n",
      "100%|██████████| 2861280/2861280 [02:09<00:00, 22095.43it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_per_N(df:pd.DataFrame, n:int, label = False):\n",
    "    data = []\n",
    "    pre_session_id = int(df['session_id'].iloc[0])\n",
    "    if label:\n",
    "        row = [0]\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            # next session id\n",
    "            if pre_session_id != int(df['session_id'].iloc[i]):\n",
    "                data.append((pre_session_id, np.array(row).reshape(-1, 6)))\n",
    "                pre_session_id, row = int(df['session_id'].iloc[i]), [0]\n",
    "            # append 5 values\n",
    "            row.append(df['song_id'].iloc[i])\n",
    "        # append last session id\n",
    "        data.append((df['session_id'].iloc[-1], np.array(row).reshape(-1, 6))) #last one\n",
    "    else:\n",
    "        row = []\n",
    "        song_id = []\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            # next session id\n",
    "            if pre_session_id != int(df['session_id'].iloc[i]):\n",
    "                data.append((pre_session_id, \n",
    "                             np.array(row).reshape(-1, 20), \n",
    "                             np.array(song_id).reshape(-1, 20)))\n",
    "                pre_session_id, row,song_id = int(df['session_id'].iloc[i]), [], []\n",
    "            # append 20 values\n",
    "            song_id.append(df['song_id'].iloc[i])\n",
    "            row.append([df['play_status'].iloc[i],\n",
    "                        df['login_type'].iloc[i],\n",
    "                        df['second_of_minute'].iloc[i],\n",
    "                        df['minute_of_hour'].iloc[i],\n",
    "                        df['hour_of_day'].iloc[i],\n",
    "                        df['month'].iloc[i], \n",
    "                        df['year'].iloc[i]])\n",
    "        # append last session id\n",
    "        data.append((df['session_id'].iloc[-1], \n",
    "                     np.array(row).reshape(-1, 20),\n",
    "                     np.array(song_id).reshape(-1, 20)))\n",
    "    return data\n",
    "\n",
    "train_source_data  = convert_per_N(train_source, 20)\n",
    "train_source_label = convert_per_N(train_target, 5, label=True)\n",
    "test_source_data   = convert_per_N(test_source, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert to dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingDatset(Dataset):\n",
    "    def __init__(self, data, label=None, train = True):\n",
    "        self.session_id = [session_id for session_id,_,_ in data]\n",
    "        self.feature    = [feature    for _,feature,_    in data]\n",
    "        self.song_id    = [song_id    for _,_,song_id    in data]\n",
    "        if train:\n",
    "            self.label  = [label for _,label in label]\n",
    "        else:\n",
    "            self.label  = [0 for _ in data]\n",
    "    def __len__(self):\n",
    "        return len(self.session_id)\n",
    "    def __getitem__(self, idx):\n",
    "        session_id = self.session_id[idx]\n",
    "        feature = torch.tensor(self.feature[idx], dtype=torch.long)\n",
    "        song_id = torch.tensor(self.song_id[idx], dtype=torch.long)\n",
    "        label = torch.tensor(self.label[idx], dtype=torch.long)\n",
    "        return {'session_id': session_id, 'feature': feature, 'song_id': song_id, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_id': 47890,\n",
       " 'feature': tensor([[ 1, 49,  0,  0,  0,  0,  0,  1, 49,  0,  0,  0,  0,  0,  1, 49,  0,  0,\n",
       "           0,  0],\n",
       "         [ 0,  1, 49,  0,  0,  0,  0,  0,  1, 49,  0,  0,  0,  0,  0,  1, 49,  0,\n",
       "           0,  0],\n",
       "         [ 0,  0,  1, 49,  0,  0,  0,  0,  0,  1, 49,  0,  0,  0,  0,  0,  1, 49,\n",
       "           0,  0],\n",
       "         [ 0,  0,  0,  1, 49,  0,  0,  0,  0,  0,  1, 49,  0,  0,  0,  0,  0,  1,\n",
       "          49,  0],\n",
       "         [ 0,  0,  0,  0,  1, 49,  0,  0,  0,  0,  0,  1, 49,  0,  0,  0,  0,  0,\n",
       "           1, 49],\n",
       "         [ 0,  0,  0,  0,  0,  1, 49,  0,  0,  0,  0,  0,  1, 49,  0,  0,  0,  0,\n",
       "           0,  1],\n",
       "         [49,  0,  0,  0,  0,  0,  1, 49,  0,  0,  0,  0,  0,  1, 49,  0,  0,  0,\n",
       "           0,  0]]),\n",
       " 'song_id': tensor([[657176, 149727, 494131,  54032, 361890, 625642,  82272, 517085, 390513,\n",
       "          662164, 452647, 637402, 286463, 172938, 118541, 428527, 478109,  41996,\n",
       "          612006, 705332]]),\n",
       " 'label': tensor([[     0, 551608, 461066, 544642,  57404, 131592]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = RankingDatset(train_source_data, train_source_label)\n",
    "train_size = int(hyperparams.get_train_size() * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "test_dataset  = RankingDatset(test_source_data, train=False)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Dataloader with batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=hyperparams.get_batch_size(), shuffle=True)\n",
    "val_dataloader   = DataLoader(val_dataset, batch_size=hyperparams.get_batch_size())\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=hyperparams.get_batch_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, batch_size, num_songs, embedding_dim, hidden_size, num_feature, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.embedding = nn.Embedding(num_songs, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim+num_feature, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, song_ids, feature):\n",
    "        embedded = self.embedding(song_ids) .squeeze(1)\n",
    "        # input feature cat with song embed\n",
    "        lstm_input = torch.cat((embedded, feature.view(self.batch_size,20,-1)), dim=2)  # Concatenate along the feature dimension\n",
    "        # Forward propagate LSTM\n",
    "        out, hidden = self.lstm(lstm_input)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        return out, hidden\n",
    "\n",
    "# Define the Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, batch_size, num_songs, embedding_dim, enc_hidden_size, hidden_size, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_songs, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim+enc_hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(20, 1)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_songs)\n",
    "\n",
    "    def forward(self, decode_song_ids, last_hidden, encoder_hidden):\n",
    "        # Forward propagate LSTM\n",
    "        embedded = self.embedding(decode_song_ids).squeeze(1) # torch.Size([64, 1, 128])\n",
    "        encoder_hidden = self.fc1(encoder_hidden.reshape(self.batch_size,-1,20)) # torch.Size([64, 256, 1])\n",
    "        lstm_input = torch.cat((embedded, encoder_hidden.view(self.batch_size,1,-1)), dim=2) # torch.Size([64, 1, 386])\n",
    "        out, lstm_hidden = self.lstm(lstm_input, last_hidden)\n",
    "        out = self.fc2(out.squeeze(1)) # torch.Size([64, 716557])\n",
    "        return out, lstm_hidden\n",
    "\n",
    "# Seq2Seq model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, song_ids, features, target_song_ids, use_teacher_forcing=True):\n",
    "        encoder_output, hidden = self.encoder(song_ids, features)\n",
    "        target_song_ids = target_song_ids.squeeze(1) # torch.Size([64, 6])\n",
    "        batch_size = target_song_ids.size(0)  # 64\n",
    "        target_len = target_song_ids.size(-1) # 6\n",
    "        target_song_size = self.decoder.fc2.out_features\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_len, target_song_size) # torch.Size([64, 6, 716557])\n",
    "        decoder_input = target_song_ids[:, 0].unsqueeze(1)  # SOS token as the first input, torch.Size([64, 1])\n",
    "        for t in range(1, target_len):\n",
    "            decoder_output, hidden = self.decoder(decoder_input.unsqueeze(1), hidden, encoder_output)\n",
    "            outputs[:, t, :] = decoder_output\n",
    "            # using teacher forcing\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = target_song_ids[:, t].unsqueeze(1)\n",
    "            else:\n",
    "                decoder_input = torch.argmax(decoder_output.squeeze(0),dim = 1).unsqueeze(1)\n",
    "        return torch.argmax(outputs, dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(hyperparams.get_batch_size(), \n",
    "                  len(list(ID_IDX.values())), \n",
    "                  hyperparams.get_embedding_dim(), \n",
    "                  hyperparams.get_hidden_size(), \n",
    "                  train_dataset[0]['feature'].shape[0], \n",
    "                  hyperparams.get_lstm_num_layers()\n",
    "                  )\n",
    "decoder = Decoder(hyperparams.get_batch_size(),\n",
    "                  len(list(ID_IDX.values())), \n",
    "                  hyperparams.get_embedding_dim(), \n",
    "                  hyperparams.get_hidden_size(), \n",
    "                  hyperparams.get_hidden_size(), \n",
    "                  hyperparams.get_lstm_num_layers()\n",
    "                  )\n",
    "model = Seq2Seq(encoder, decoder).to(hyperparams.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 6]),\n",
       " tensor([[     0, 627674, 217020, 131695, 131695, 131695],\n",
       "         [     0,  43503, 502994, 472149, 639739, 585053],\n",
       "         [     0,  43503, 169674, 169674, 217020, 585053],\n",
       "         [     0, 696212, 231735, 231735, 272798, 272798],\n",
       "         [     0,  43503, 512256, 512256, 667592, 137733],\n",
       "         [     0,  43503, 231735, 169674, 169674, 169674],\n",
       "         [     0,  43503, 144857, 667592, 667592, 137733],\n",
       "         [     0,  43503, 217020, 585053, 667592, 585053],\n",
       "         [     0,  43503, 231735, 217020, 667592, 634661],\n",
       "         [     0,  43503, 144857, 355345, 137733, 137733],\n",
       "         [     0,  43503, 169674, 169674, 169674, 169674],\n",
       "         [     0,  43503, 231735, 512256, 639739, 169674],\n",
       "         [     0, 696212, 231735, 231735, 231735, 231232],\n",
       "         [     0,  43503, 231735, 217020, 169674, 639739],\n",
       "         [     0,  43503, 562567, 169674, 634661, 634661],\n",
       "         [     0,  43503, 217020, 667592, 667592, 634661]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def testing_model(model=model, train_dataloader=train_dataloader):\n",
    "    batch_sample = next(iter(train_dataloader))\n",
    "    song_ids = batch_sample['song_id'].to(hyperparams.get_device())\n",
    "    features = batch_sample['feature'].to(hyperparams.get_device())\n",
    "    target   = batch_sample['label'].to(hyperparams.get_device())\n",
    "    # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        output = model(song_ids, features, target)\n",
    "        return output.shape, output\n",
    "testing_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDCG Loss: 0.6299999952316284\n"
     ]
    }
   ],
   "source": [
    "class NDCGLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NDCGLoss, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, labels):\n",
    "        # Calculate nDCG loss\n",
    "        # Compare predictions and labels element-wise\n",
    "        gain = (predictions != labels).float()\n",
    "        weightage = torch.tensor([1.0, 0.63, 0.5, 0.43, 0.38]).float()\n",
    "        nDCG = torch.dot(gain, weightage)\n",
    "        return nDCG\n",
    "\n",
    "def test_NDCGLoss():\n",
    "    # Example usage:\n",
    "    predictions = torch.tensor([0, 5, 3, 5, 2, 1])  # Example predicted scores\n",
    "    labels      = torch.tensor([0, 5, 4, 5, 2, 1])  # Example true relevance scores \n",
    "    # Define nDCG loss criterion\n",
    "    criterion = NDCGLoss()  \n",
    "    # Calculate nDCG loss\n",
    "    loss = criterion(predictions[1:], labels[1:])\n",
    "    print(f\"nDCG Loss: {loss.item()}\")\n",
    "test_NDCGLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute coverage\n",
    "# torch.unique(torch.tensor([[0, 1, 2, 3, 4, 5],[6, 7, 8, 9, 10, 11]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = NDCGLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=hyperparams.get_learning_rate())\n",
    "total_steps = len(train_dataloader) * hyperparams.get_epochs()\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28613 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 3D and 1D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb 儲存格 27\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(hyperparams\u001b[39m.\u001b[39mget_epochs()):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mhyperparams\u001b[39m.\u001b[39mget_epochs()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m         train_loss \u001b[39m=\u001b[39m train(model, train_dataloader, optimizer, scheduler, hyperparams\u001b[39m.\u001b[39;49mget_device())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m         valid_loss \u001b[39m=\u001b[39m evaluate(model, val_dataloader, hyperparams\u001b[39m.\u001b[39mget_device())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb 儲存格 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m target   \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(song_ids, features, target)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs[\u001b[39m1\u001b[39;49m:]\u001b[39m.\u001b[39;49mcpu(), target[\u001b[39m1\u001b[39;49m:]\u001b[39m.\u001b[39;49mcpu())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m total_loss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb 儲存格 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m gain \u001b[39m=\u001b[39m (predictions \u001b[39m!=\u001b[39m labels)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m weightage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1.0\u001b[39m, \u001b[39m0.63\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.43\u001b[39m, \u001b[39m0.38\u001b[39m])\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m nDCG \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mdot(gain, weightage)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2254574343285079746f72636829227d/work/u5110390/kkBox_game/notebook/kkbox_preprocessing.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m nDCG\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 3D and 1D tensors"
     ]
    }
   ],
   "source": [
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        song_ids = batch['song_id'].to(device)\n",
    "        features = batch['feature'].to(device)\n",
    "        target   = batch['label'].to(device)\n",
    "        outputs = model(song_ids, features, target)\n",
    "        loss = loss_fn(outputs[1:].cpu(), target[1:].cpu())\n",
    "        total_loss+=loss.items()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    return total_loss\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            song_ids = batch['song_id'].to(device)\n",
    "            features = batch['feature'].to(device)\n",
    "            target   = batch['label'].to(device)\n",
    "            outputs = model(song_ids, features, target)\n",
    "            loss = loss_fn(outputs[1:], target[1:])\n",
    "            total_loss+=loss.items()\n",
    "    return total_loss\n",
    "\n",
    "for epoch in range(hyperparams.get_epochs()):\n",
    "        print(f\"Epoch {epoch + 1}/{hyperparams.get_epochs()}\")\n",
    "        train_loss = train(model, train_dataloader, optimizer, scheduler, hyperparams.get_device())\n",
    "        valid_loss = evaluate(model, val_dataloader, hyperparams.get_device())\n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation loss: {valid_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict tesing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Submittion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
